{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1) a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import X and y from csv file\n",
    "def read_logistic_data(filename):\n",
    "    my_data = genfromtxt(filename, delimiter=';')\n",
    "    X = []\n",
    "    y= []\n",
    "    for i in range(len(my_data)):\n",
    "        new_data = my_data[i]\n",
    "        y.append([new_data[-1]])\n",
    "        X.append(np.delete(new_data, -1))\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = read_logistic_data('digits123-1.csv')\n",
    "X_test, y_test = read_logistic_data('digits123-2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "INPUT: \n",
    "- training data (features and class concatenated)\n",
    "\n",
    "OUTPUT:\n",
    "- dictionary where classes are keys, with training examples\n",
    "  corresponding to that class as values.\n",
    "'''\n",
    "def separate_classes(data):\n",
    "    classdict = dict()\n",
    "    for i in range(len(data)):\n",
    "        x = data[i]\n",
    "        if (x[-1] not in classdict):\n",
    "            classdict[x[-1]] = []\n",
    "        classdict[x[-1]].append(x)\n",
    "    \n",
    "    return classdict\n",
    "\n",
    "classes = separate_classes(np.concatenate((X_train, y_train), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "INPUT:\n",
    "- numpy array\n",
    "\n",
    "OUTPUT:\n",
    "- mean of values in array\n",
    "- variance of values in array\n",
    "'''\n",
    "def mean_var(x):\n",
    "    mean = sum(x)/len(x) \n",
    "    variance = sum(((x-mean)**2))/len(x)   \n",
    "    return mean, variance    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "INPUT:\n",
    "- class\n",
    "\n",
    "OUTPUT:\n",
    "- dictionary where classes are keys, with (mean, variance) list\n",
    "  of training examples corresponding to correct class.\n",
    "'''\n",
    "def mean_var_class(c):\n",
    "    mean_var_list = list()\n",
    "    \n",
    "    # loop over every attribute\n",
    "    for i in range(len(classes[c][0])-1):\n",
    "        mean_var_attribute = np.array([])\n",
    "        # loop over every training example\n",
    "        for j in range(len(classes[c])):\n",
    "            mean_var_attribute = np.concatenate((mean_var_attribute, np.array([classes[c][j][i]])), axis=0)\n",
    "        mean_var_list.append(mean_var(mean_var_attribute))\n",
    "    \n",
    "    return mean_var_list\n",
    "\n",
    "\n",
    "# create dict: key = class, entry = list with mean and variance for every feature    \n",
    "mean_var_dict = {1.0 : mean_var_class(1.0), 2.0: mean_var_class(2.0), 3.0 : mean_var_class(3.0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "INPUT:\n",
    "- mean\n",
    "- variance\n",
    "- value for feature x\n",
    "\n",
    "OUTPUT:\n",
    "- probability density function\n",
    "'''\n",
    "def pdf(mean, variance, x):\n",
    "    # ignore training examples with value 0 for mean and variance,\n",
    "    # i.e. return p = 1, so that multiplying with p does not change value.\n",
    "    if ((mean == 0) & (variance == 0)):\n",
    "        p = 1\n",
    "    else:\n",
    "        p = (1/(math.sqrt(2*variance*math.pi)))*math.e**-(((x-mean)**2)/(2*variance))\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1.0: 3.952058804347397e-47, 2.0: 2.1858205950974448e-64, 3.0: 1.8196239624211918e-63}\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "INPUT:\n",
    "- list with classes\n",
    "- test instance x\n",
    "\n",
    "OUTPUT:\n",
    "- dictionary where classes are keys, with p that x\n",
    "  is in class as value.\n",
    "'''\n",
    "def p_x_given_class(classes, x):\n",
    "    probabilities = {}\n",
    "    for c in classes:     \n",
    "        p = 1\n",
    "        for i in range(len(x)):\n",
    "            feature_train = x[i]\n",
    "            feature_mean = mean_var_dict[c][i][0]\n",
    "            feature_var = mean_var_dict[c][i][1]\n",
    "            p *= pdf(feature_mean, feature_var, feature_train)\n",
    "        probabilities[c] = p\n",
    "            \n",
    "    return probabilities\n",
    "\n",
    "'''\n",
    "INPUT:\n",
    "- list with classes\n",
    "- test instance x\n",
    "\n",
    "OUTPUT:\n",
    "- prediction for class\n",
    "'''\n",
    "def prediction(classes, x):    \n",
    "    p_x_given_c = p_x_given_class(classes,x)\n",
    "    \n",
    "    # find n of training examples\n",
    "    length = 0\n",
    "    for i in classes:\n",
    "        length += len(classes[i])\n",
    "        \n",
    "    # find value for P(x|c1) + P(x|c2) + ... + P(x|cn)\n",
    "    divide_by = 0    \n",
    "    for i in classes:\n",
    "        divide_by += p_x_given_c[i] * len(classes[i])/float(length)\n",
    "         \n",
    "    for i in p_x_given_c:\n",
    "        p_x_given_c[i] = ((p_x_given_c[i] * len(classes[i])/float(length)) / divide_by)\n",
    "        \n",
    "    return max(p_x_given_c.iteritems(), key=operator.itemgetter(1))[0]\n",
    "\n",
    "print class_probabilities(classes, X_train[0])\n",
    "print prediction(classes, X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct:    172\n",
      "False:      68\n",
      "Accurracy:  0.71667\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "INPUT:\n",
    "- test data: features\n",
    "- test data: correct classes\n",
    "\n",
    "OUTPUT:\n",
    "- n of correctly classified instances\n",
    "- n of incorrectly classified instances\n",
    "- list with index of incorrectly classified instances\n",
    "'''\n",
    "def evaluation_gaussian_nb(X_test, y_test):\n",
    "    true = 0\n",
    "    false = 0   \n",
    "    false_instances = list()\n",
    "    for i in range(len(X_test)):\n",
    "        predicted = prediction(classes, X_test[i])\n",
    "        actual = y_train[i][0]\n",
    "        if predicted == actual:\n",
    "            true += 1\n",
    "        if predicted != actual:\n",
    "            false += 1\n",
    "            false_instances.append(i)\n",
    "             \n",
    "    return true, false, false_instances\n",
    "\n",
    "true, false, false_instances = evaluation_gaussian_nb(X_test, y_test)\n",
    "\n",
    "print 'Correct:   ', true\n",
    "print 'False:     ', false\n",
    "print 'Accurracy: ', round((float(true)/float(false + true)), 5)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1) b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1.0: 8.7727579919187879e-68, 2.0: 7.6757727494372779e-66, 3.0: 0.0}\n",
      "prediction:  2.0\n",
      "actual:      1.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 3.001399040509384e-79, 2.0: 2.3129165503814674e-70, 3.0: 0.0}\n",
      "prediction:  2.0\n",
      "actual:      1.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 3.2307747381093167e-70, 2.0: 1.6815889701900517e-59, 3.0: 4.3221550669138766e-96}\n",
      "prediction:  2.0\n",
      "actual:      1.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 1.7349709895829556e-71, 2.0: 4.0829056283834716e-48, 3.0: 3.1084867736730191e-71}\n",
      "prediction:  2.0\n",
      "actual:      1.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 1.0158273915718126e-97, 2.0: 3.1710937831898381e-111, 3.0: 1.5007752556678846e-86}\n",
      "prediction:  3.0\n",
      "actual:      1.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 7.4253158850782516e-159, 2.0: 1.7929702473286409e-73, 3.0: 7.2476911246904752e-89}\n",
      "prediction:  2.0\n",
      "actual:      1.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 1.1998197818627497e-112, 2.0: 2.5563663347455557e-74, 3.0: 1.7801093610007367e-71}\n",
      "prediction:  3.0\n",
      "actual:      1.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 5.8500106071067422e-81, 2.0: 5.6292388447744595e-60, 3.0: 4.8900928949325589e-66}\n",
      "prediction:  2.0\n",
      "actual:      1.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 8.6354945936875125e-261, 2.0: 1.5466565558386824e-50, 3.0: 1.8378501401565155e-68}\n",
      "prediction:  2.0\n",
      "actual:      1.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 9.0041058237530378e-102, 2.0: 6.4278267663643173e-53, 3.0: 9.9914267691926412e-61}\n",
      "prediction:  2.0\n",
      "actual:      1.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 4.8796182053587032e-89, 2.0: 2.8608629128976402e-49, 3.0: 2.1937773021062743e-56}\n",
      "prediction:  2.0\n",
      "actual:      1.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 3.1222141773252456e-108, 2.0: 3.203163852345763e-49, 3.0: 9.6613086826328174e-59}\n",
      "prediction:  2.0\n",
      "actual:      1.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 1.0051492087937085e-104, 2.0: 2.4896700739675672e-48, 3.0: 2.9865760619737867e-57}\n",
      "prediction:  2.0\n",
      "actual:      1.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 2.3055592114772572e-95, 2.0: 4.3464747865890484e-55, 3.0: 3.6284700838106362e-78}\n",
      "prediction:  2.0\n",
      "actual:      1.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 1.8610926118105462e-80, 2.0: 1.3524046530707529e-55, 3.0: 6.2398410133370666e-70}\n",
      "prediction:  2.0\n",
      "actual:      1.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 6.8041254155903152e-69, 2.0: 2.913022754196164e-51, 3.0: 2.8492805111638019e-55}\n",
      "prediction:  2.0\n",
      "actual:      1.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 3.1439978732073161e-54, 2.0: 1.0570574249813407e-49, 3.0: 1.6292216430517496e-59}\n",
      "prediction:  2.0\n",
      "actual:      1.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 9.2914534931736345e-57, 2.0: 7.0793377518233898e-58, 3.0: 2.5464701760764647e-75}\n",
      "prediction:  1.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 1.8773452434476504e-65, 2.0: 8.1686791140974313e-99, 3.0: 3.0186080692137625e-102}\n",
      "prediction:  1.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 3.9770450736651545e-91, 2.0: 4.0375888175308962e-136, 3.0: 5.4676591743940605e-267}\n",
      "prediction:  1.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 3.3167485501579029e-76, 2.0: 2.4711011956003167e-87, 3.0: 7.7620790700829526e-131}\n",
      "prediction:  1.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 6.749826909054829e-76, 2.0: 4.000333043084926e-83, 3.0: 7.7002475207282224e-106}\n",
      "prediction:  1.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 3.691835607160711e-72, 2.0: 1.5404298514459247e-79, 3.0: 7.0655402299790224e-67}\n",
      "prediction:  3.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 1.487611626329201e-223, 2.0: 2.509590036225567e-77, 3.0: 8.3163457590443719e-63}\n",
      "prediction:  3.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 4.9482024209982935e-114, 2.0: 1.7515376582074152e-59, 3.0: 3.1442593712485011e-47}\n",
      "prediction:  3.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 1.5201025870906621e-258, 2.0: 1.9130675763908003e-73, 3.0: 3.578748382061076e-46}\n",
      "prediction:  3.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 3.0975037165122663e-119, 2.0: 1.2835903457529903e-93, 3.0: 2.2946233019607556e-54}\n",
      "prediction:  3.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 4.6882482361584676e-81, 2.0: 1.1592713501325441e-65, 3.0: 5.8725387602952605e-46}\n",
      "prediction:  3.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 2.84142085277941e-89, 2.0: 4.8914735380758933e-55, 3.0: 2.8405525190120158e-45}\n",
      "prediction:  3.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 1.5345130248853312e-73, 2.0: 2.8774032034101692e-60, 3.0: 1.9188036762533989e-46}\n",
      "prediction:  3.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 1.7786446235772082e-72, 2.0: 5.8155240345285589e-60, 3.0: 4.0640988702235393e-46}\n",
      "prediction:  3.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 0.0, 2.0: 2.6973518525760969e-57, 3.0: 6.9849506236001519e-49}\n",
      "prediction:  3.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 1.9449067508358385e-254, 2.0: 2.1128667746943859e-59, 3.0: 2.207279198073705e-51}\n",
      "prediction:  3.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 2.4371182399403057e-81, 2.0: 2.2091046147391662e-60, 3.0: 1.5510536103121789e-49}\n",
      "prediction:  3.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 0.0, 2.0: 9.4517980573483472e-61, 3.0: 3.1421666558808408e-56}\n",
      "prediction:  3.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 2.0884894300551267e-262, 2.0: 2.3845340872877306e-68, 3.0: 1.6910418366755114e-50}\n",
      "prediction:  3.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 0.0, 2.0: 7.7080052051512871e-74, 3.0: 5.484559096011328e-65}\n",
      "prediction:  3.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 0.0, 2.0: 3.108975542220664e-114, 3.0: 7.9270332163978547e-59}\n",
      "prediction:  3.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 0.0, 2.0: 5.584085003413195e-65, 3.0: 2.1074849772800715e-56}\n",
      "prediction:  3.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 0.0, 2.0: 3.1576420243218483e-70, 3.0: 3.5405303776617214e-57}\n",
      "prediction:  3.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 9.58616379873225e-138, 2.0: 3.4274631583991827e-60, 3.0: 6.0220750992684315e-45}\n",
      "prediction:  3.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 0.0, 2.0: 1.4395063641904123e-68, 3.0: 2.1957781754755385e-50}\n",
      "prediction:  3.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 0.0, 2.0: 2.8595646992367577e-58, 3.0: 7.5846822574196622e-55}\n",
      "prediction:  3.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 6.9441826098041543e-137, 2.0: 1.73794620087789e-85, 3.0: 2.7074085835420991e-55}\n",
      "prediction:  3.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 7.0438240899299421e-197, 2.0: 3.3728717544226176e-60, 3.0: 2.2092273866430544e-46}\n",
      "prediction:  3.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 0.0, 2.0: 2.1242705476992601e-57, 3.0: 7.5850721300307104e-54}\n",
      "prediction:  3.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 8.6217342036279884e-88, 2.0: 3.0455002779624494e-64, 3.0: 1.2085752743510483e-54}\n",
      "prediction:  3.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 7.5686740666723066e-183, 2.0: 1.8272558288153043e-61, 3.0: 2.2779430029840573e-47}\n",
      "prediction:  3.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 0.0, 2.0: 2.032299960049492e-75, 3.0: 3.9680944471852875e-63}\n",
      "prediction:  3.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 5.7581616239316685e-101, 2.0: 8.2715827976244488e-167, 3.0: 1.1983963404132753e-62}\n",
      "prediction:  3.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 5.2762742582043459e-100, 2.0: 6.0319220162517355e-56, 3.0: 1.1346920089008999e-46}\n",
      "prediction:  3.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 5.9795499923483839e-66, 2.0: 2.1518638108974698e-61, 3.0: 5.5421173956609792e-46}\n",
      "prediction:  3.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 7.3961792838162387e-97, 2.0: 9.9911404026496568e-61, 3.0: 1.3851169599964496e-43}\n",
      "prediction:  3.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 7.1045995181152656e-92, 2.0: 4.2195063688520329e-63, 3.0: 1.0496965587464141e-45}\n",
      "prediction:  3.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 2.2330311539195686e-302, 2.0: 2.9100442580173868e-58, 3.0: 2.9182261891174449e-49}\n",
      "prediction:  3.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 2.3465456847960053e-73, 2.0: 4.9192759440996995e-61, 3.0: 1.1392570278708061e-44}\n",
      "prediction:  3.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 2.4026736509380486e-265, 2.0: 1.1029818831324054e-99, 3.0: 4.3393454509661982e-46}\n",
      "prediction:  3.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 5.7426215194052729e-145, 2.0: 8.9888308535361045e-81, 3.0: 1.4588767139269695e-44}\n",
      "prediction:  3.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 1.9237148278510621e-89, 2.0: 1.3437822806321973e-58, 3.0: 3.2659661053332847e-44}\n",
      "prediction:  3.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 2.3387996474052396e-92, 2.0: 3.8702114837204309e-62, 3.0: 3.7459629876607708e-43}\n",
      "prediction:  3.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 6.9852208931201833e-288, 2.0: 1.6495083341395821e-58, 3.0: 2.9530219694539068e-48}\n",
      "prediction:  3.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 1.6454208311470116e-223, 2.0: 4.7018677916193124e-63, 3.0: 9.6700095423075916e-54}\n",
      "prediction:  3.0\n",
      "actual:      2.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 3.2166395303722944e-125, 2.0: 1.0715257054500925e-59, 3.0: 6.4277543967067417e-61}\n",
      "prediction:  2.0\n",
      "actual:      3.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 9.5227920956602433e-106, 2.0: 3.9465386330828829e-83, 3.0: 1.7865733003029656e-117}\n",
      "prediction:  2.0\n",
      "actual:      3.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 6.9761174528751587e-88, 2.0: 4.6661177402729388e-80, 3.0: 5.3647642614248893e-83}\n",
      "prediction:  2.0\n",
      "actual:      3.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 1.6584380400293664e-106, 2.0: 5.360385631451861e-89, 3.0: 1.4803197654059445e-187}\n",
      "prediction:  2.0\n",
      "actual:      3.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 9.8485919284844514e-62, 2.0: 4.1824303499089289e-67, 3.0: 5.358146910852933e-71}\n",
      "prediction:  1.0\n",
      "actual:      3.0\n",
      "------------------------------------------------------------------------\n",
      "{1.0: 2.6146737085479762e-73, 2.0: 8.8212353914639219e-94, 3.0: 5.2068252522731005e-92}\n",
      "prediction:  1.0\n",
      "actual:      3.0\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# pretty print misclassified instances to obtain a better understanding of underlying issues.\n",
    "c = classes\n",
    "for i in false_instances:\n",
    "    print class_probabilities(c, X_test[i])\n",
    "    print 'prediction: ', prediction(c, X_test[i])\n",
    "    print 'actual:     ',y_train[i][0]\n",
    "    print '------------------------------------------------------------------------'    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "False per class:\n",
    "1     17/68\n",
    "2     45/68\n",
    "3     6/68\n",
    "\n",
    "Conclusion: class 2 gets misclassified most often by far. Also, the algorithm seems to assign a relatively high probability (to the incorrect class) when misclassifying class 2.\n",
    "\n",
    "Now we have to find out where the algorithm gets it wrong.\n",
    "\n",
    "class 2 misclassified as:\n",
    "1     5/45\n",
    "2     40/45\n",
    "\n",
    "Conclusion: the main problem is that class 2 gets misclassified as class 3. This specific type of error accounts for 40 out of the 68 errors. Besides being the most frequent error, these examples also have the highest probability of the misclassified instances.  \n",
    "\n",
    "In almost all the cases where class 2 gets misclassified as class 3, the probability for class 1 is zero (or many orders of magnitude smaller than the other probabilities), and the probability for class 2 and class 3 are relatively close to each other ('relatively' meaning within 10 orders of magnitude).\n",
    "\n",
    "Class 2 consists of 96 training examples. Both class 1 and class 2 consist of 102 training examples. When training a Gaussian Naive Bayes classifier on this slightly uneven spread dataset, there is a bias for class 1 / class 2 (because there are more instances of these classes to be found than class 2). To improve accurracy, we can add more training examples of class 2 so that this bias will disappear.\n",
    "\n",
    "Another conclusion that can be drawn: the algorithm finds it more difficult to distinguish between 2 and 3 than between 2 and 1. The shape for the number 1 is very easy: a straight line. The shape of numbers 2 and 3 have more overlap, therefore it is harder to distinguish between these classes. Solution: add more training examples to better learn the different characteristics. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

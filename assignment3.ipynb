{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leren: Programming assignment 3\n",
    "** This assignment can be done in teams of 2 **\n",
    "\n",
    "**Student 1:**  <span style=\"color:red\">Tycho Koster</span> (<span style=\"color:red\">10667687</span>)<br>\n",
    "**Student 2:** <span style=\"color:red\">David Stap</span> (<span style=\"color:red\">10608516</span>)<br>\n",
    "\n",
    "-----------------------------------\n",
    "This notebook provides a template for your programming assignment 3. You may want to use parts of your code from the previous assignment(s) as a starting point for this assignment. \n",
    "\n",
    "The code you hand-in should follow the structure from this document. Each part of the assignment has its own cell, you are free to add more cells. Note that the structure corresponds with the structure from the actual programming assignment. Make sure you read this for the full explanation of what is expected of you.\n",
    "\n",
    "**Submission:**\n",
    "\n",
    "* Make sure your code can be run from top to bottom without errors.\n",
    "* Include your data files in the zip file.\n",
    "* Comment your code\n",
    "\n",
    "One way be sure you code can be run without errors is by quiting iPython completely and then restart iPython and run all cells again (you can do this by going to the menu bar above: Cell > Run all). This way you make sure that no old definitions of functions or values of variables are left (that your program might still be using).\n",
    "\n",
    "-----------------------------------\n",
    "\n",
    "If you have any questions ask your teaching assistent. We are here for you.\n",
    "\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularized Logistic Regression\n",
    "a) Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "\n",
    "# add data\n",
    "# X1  X2  X3  Y\n",
    "# 10  4   4   0\n",
    "# 7   3   3   0 \n",
    "# 5   4   2   1\n",
    "# 2   3   1   1\n",
    "def read_logistic_data():\n",
    "    x = []\n",
    "    y= []\n",
    "    y.append(0)\n",
    "    y.append(0)\n",
    "    y.append(1)\n",
    "    y.append(1)\n",
    "    x.append([10.0, 4.0, 4.0])\n",
    "    x.append([7.0, 3.0, 3.0])\n",
    "    x.append([5.0, 4.0, 2.0])\n",
    "    x.append([2.0, 3.0, 1.0])    \n",
    "    return x, y\n",
    "\n",
    "\n",
    "def create_theta_array(x):\n",
    "    theta = [0.5]\n",
    "    for i in range(len(x)):\n",
    "        theta.append(0.5)\n",
    "    return theta\n",
    "\n",
    "\n",
    "x, y = read_logistic_data()\n",
    "theta_array = create_theta_array(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "gradient_function_logistic\n",
    "Input: alpha (learning rate), theta_array (list of theta values), x (list of multiple features with values), y (list of values)\n",
    "Output: gradient for every theta in array\n",
    "'''\n",
    "\n",
    "def gradient_function_logistic(alpha, theta_array, theta, x, y):\n",
    "    m = len(x)\n",
    "    totalsum = 0\n",
    "    for i in range(0, len(x[0])):\n",
    "        temp_x = []\n",
    "        #temporary x for the values of all features at that specific index\n",
    "        for j in range(len(x)):\n",
    "            temp_x.append(x[j][i])\n",
    "        if theta == 0:\n",
    "            totalsum += (Hx_logistic(theta_array, temp_x) - y[i])\n",
    "        else:\n",
    "            totalsum += (Hx_logistic(theta_array, temp_x) - y[i])*x[theta-1][i]\n",
    "    return (alpha*totalsum)/m\n",
    "    \n",
    "'''\n",
    "Hx_logistic\n",
    "Input: theta_array (list of theta values), x (list of values)\n",
    "Output: prediction of y with logistic hypotheses calculations\n",
    "'''\n",
    "def Hx_logistic(theta_array, x):\n",
    "    exponent = theta_array[0]\n",
    "    for i in range(1, len(theta_array)):\n",
    "        exponent += theta_array[i]*x[i-1]\n",
    "    e = -exponent\n",
    "    return 1.0/(1 + math.exp(e))\n",
    "\n",
    "'''\n",
    "update_theta_logistic\n",
    "Input: alpha (learning rate), theta_array (list of theta values), x (list of multiple features with values), y (list of values),\n",
    "iterations (number of iterations to be done)\n",
    "Output: All values of theta after the amount of iterations with the use of logistic regression.\n",
    "'''\n",
    "def update_theta_logistic(alpha, theta_array, x, y, iterations):\n",
    "    costs = []\n",
    "    costs.append(cost(theta_array, x, y))\n",
    "    for i in range(iterations):\n",
    "        for j in range(len(theta_array)):\n",
    "            theta_array[j] -= gradient_function_logistic(alpha, theta_array,j, x, y)\n",
    "        costs.append(cost(theta_array, x, y))\n",
    "    return theta_array, costs\n",
    "\n",
    "def hypothesis(theta, training_example):\n",
    "    totalsum = 0.0\n",
    "    for i in range(len(theta[1:])):\n",
    "        totalsum += theta[i]*training_example[i]\n",
    "    # + theta_0 * 1\n",
    "    totalsum+=theta[0]  \n",
    "    return 1.0/(1 + math.exp(-totalsum))\n",
    "    \n",
    "    \n",
    "def cost(theta, x, y):\n",
    "    cost = 0.0\n",
    "    for t in range(len(x)):\n",
    "        if y[t] == 1:\n",
    "            cost += math.log10(hypothesis(theta, x[t]))\n",
    "        if y[t] == 0:\n",
    "            cost += math.log10(1-hypothesis(theta, x[t]))\n",
    "        \n",
    "    return (-1.0/len(x)) * cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.49502293901017974,\n",
       "  0.46509236400983045,\n",
       "  0.4750796202086097,\n",
       "  0.4775725918897131],\n",
       " [1.7950707304149853, 1.7399201079007602])"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_theta_logistic(0.01, theta_array, x, y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_theta(alpha, theta, x, y, iterations):\n",
    "    \n",
    "    errors = []\n",
    "    for t in range(len(x)):\n",
    "        errors.append(hypothesis(theta, x[t]) - y[t])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return errors\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9999251537724895,\n",
       " 0.9990889488055994,\n",
       " -0.002472623156634657,\n",
       " -0.02931223075135636]"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_theta(0.01, theta_array, x, y, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999925153772\n",
      "0.999088948806\n",
      "0.997527376843\n",
      "0.970687769249\n"
     ]
    }
   ],
   "source": [
    "print hypothesis(theta_array, x[0])\n",
    "print hypothesis(theta_array, x[1])\n",
    "print hypothesis(theta_array, x[2])\n",
    "print hypothesis(theta_array, x[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.495081926878\n"
     ]
    }
   ],
   "source": [
    "x1 = hypothesis(theta_array, x[0])\n",
    "x2 = hypothesis(theta_array, x[1])\n",
    "x3 = hypothesis(theta_array, x[2])-1\n",
    "x4 = hypothesis(theta_array, x[3])-1\n",
    "\n",
    "print 0.5 - 0.01 * (1/4.0)*(x1+x2+x3+x4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Two small datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:**\n",
    "\n",
    "[You discussion comes here]\n",
    "\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def sigmoid_derivative(z):\n",
    "    return x*(1-x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.50672313])"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Input: \n",
    "- Input value(s) X\n",
    "- List with weights for hidden layer(s) W\n",
    "- Weights for final layer W_output (can be of a different dimension than\n",
    "  W, because n of output values can be different than n of nodes in \n",
    "  hidden layers)\n",
    "Output: \n",
    "- activation value(s) of y \n",
    "'''\n",
    "def forward(X, W, W_output):    \n",
    "    temp = list()\n",
    "    temp.append(X)    \n",
    "    for i in range(len(W)):\n",
    "        temp.append(sigmoid(np.dot(temp[i], W[i])))\n",
    "        \n",
    "    return sigmoid(np.dot(temp[-1], W_output))\n",
    "    \n",
    "#example run: calculate activation of Y for neural network in written3\n",
    "X = np.array([[-5]])\n",
    "W = np.array([[0.2]])\n",
    "W_output = np.array([[0.1]])\n",
    "\n",
    "forward(X, W, W_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.33253144,  0.50703863,  0.51807777])"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# more fancy example run: calculate activation of y where:\n",
    "\n",
    "inputLayerSize = 2\n",
    "outputLayerSize = 3\n",
    "hiddenLayerSize = 3\n",
    "hiddenLayerDepth = 100\n",
    "\n",
    "# create random weight values for all hidden layers\n",
    "W = list()\n",
    "W.append(np.random.randn(inputLayerSize, hiddenLayerSize))\n",
    "if hiddenLayerSize > 1:\n",
    "    for i in range(hiddenLayerDepth):\n",
    "        W.append(np.random.randn(hiddenLayerSize, hiddenLayerSize))\n",
    "\n",
    "W_output = np.random.randn(hiddenLayerSize, outputLayerSize)\n",
    "\n",
    "X = np.array([1,2])\n",
    "\n",
    "forward(X, W, W_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Backpropagation on two logistic units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Complete backpropagation on handwritten digit recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion:**\n",
    "\n",
    "[You discussion comes here]\n",
    "\n",
    "-----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputLayerSize = 2\n",
    "outputLayerSize = 1\n",
    "hiddenLayerSize = 3\n",
    "   \n",
    "W1 = np.random.randn(inputLayerSize, hiddenLayerSize)\n",
    "W2 = np.random.randn(hiddenLayerSize, outputLayerSize)\n",
    "     \n",
    "def forward(X):\n",
    "    z2 = np.dot(X, W1)\n",
    "    a2 = sigmoid(z2)\n",
    "    z3 = np.dot(a2, W2)\n",
    "    return sigmoid(z3)\n",
    "    \n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def sigmoid_derivative(z):\n",
    "    return x*(1-x)\n",
    "\n",
    "def costFunctionPrime(X, y):\n",
    "    yHat = forward(X)\n",
    "\n",
    "    delta3 = np.multiply(-(y-yHat), sigmoid_derivative(z3))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
